# Capstone 3: Интеграция реальных моделей в веб-интерфейс

## Цель
Интегрировать обученные модели (LSTM и CNN) из Jupyter ноутбуков в HTML веб-интерфейс для реальных предсказаний вместо симуляции.

## Текущее состояние проекта

### Выполнено (Checkpoint 1-2):
- ✅ Обучены модели LSTM и CNN в ноутбуках
- ✅ Модели сохранены как `best_lstm_model.pth` и `best_cnn_model.pth`
- ✅ Создан HTML интерфейс с симуляцией предсказаний
- ✅ Реализована визуализация внимания (attention)
- ✅ Добавлено сравнение моделей

### Требуется для Capstone 3:
- ⏳ Интеграция реальных моделей PyTorch
- ⏳ Создание FastAPI бэкенда
- ⏳ Предобработка текста (vocab, tokenization)
- ⏳ Загрузка GloVe embeddings
- ⏳ Подключение фронтенда к бэкенду

## План выполнения

### Этап 1: Подготовка инфраструктуры
1. Создать структуру папок для бэкенда
2. Выделить общий код предобработки из ноутбуков
3. Создать модули для моделей (LSTM, CNN)
4. Создать утилиты для загрузки vocab и embeddings

### Этап 2: FastAPI бэкенд
1. Создать FastAPI приложение
2. Эндпоинт для предсказания LSTM
3. Эндпоинт для предсказания CNN
4. Эндпоинт для сравнения всех моделей
5. CORS настройки для фронтенда

### Этап 3: Интеграция с фронтендом
1. Обновить HTML для работы с API
2. Заменить симуляцию на реальные запросы
3. Обработка ошибок и загрузки
4. Тестирование интеграции

### Этап 4: Оптимизация и документация
1. Кэширование моделей
2. Оптимизация производительности
3. Документация API
4. Инструкции по запуску

## Архитектура решения

```
┌─────────────┐
│  HTML/JS    │  ← Фронтенд (docs/index.html)
│  Frontend   │
└──────┬──────┘
       │ HTTP POST /predict
       │
┌──────▼──────────────────┐
│   FastAPI Backend       │
│  ┌────────────────────┐ │
│  │  /predict/lstm     │ │
│  │  /predict/cnn      │ │
│  │  /predict/all      │ │
│  └────────────────────┘ │
└──────┬──────────────────┘
       │
┌──────▼──────────────────┐
│  Model Inference         │
│  ┌──────────┐ ┌────────┐│
│  │  LSTM    │ │  CNN   ││
│  │  Model   │ │  Model ││
│  └──────────┘ └────────┘│
│  ┌────────────────────┐ │
│  │  Preprocessing     │ │
│  │  (vocab, tokenize) │ │
│  └────────────────────┘ │
└──────────────────────────┘
```

## Технические детали

### Модели
- **LSTM**: BiLSTM с GloVe 100d embeddings
- **CNN**: 1D convolutions с фильтрами [3, 4, 5]

### Предобработка
- Токенизация через vocab из обучения
- Максимальная длина: 256 токенов
- Padding для коротких текстов

### API Endpoints
- `POST /api/predict/lstm` - предсказание LSTM
- `POST /api/predict/cnn` - предсказание CNN  
- `POST /api/predict/all` - сравнение всех моделей
- `GET /api/health` - проверка статуса

## Файловая структура

```
.
├── backend/
│   ├── __init__.py
│   ├── main.py              # FastAPI приложение
│   ├── models/
│   │   ├── __init__.py
│   │   ├── lstm_model.py    # LSTM модель
│   │   └── cnn_model.py     # CNN модель
│   ├── preprocessing/
│   │   ├── __init__.py
│   │   ├── text_processor.py # Токенизация и предобработка
│   │   └── vocab_loader.py   # Загрузка vocab
│   └── utils/
│       ├── __init__.py
│       └── model_loader.py   # Загрузка моделей
├── models/                   # Сохраненные модели
│   ├── best_lstm_model.pth
│   └── best_cnn_model.pth
├── vocab/                    # Vocab и embeddings
│   ├── vocab.json
│   └── glove_embeddings.npy
└── docs/
    └── index.html           # Обновленный фронтенд
```

## Критерии успеха

- ✅ Модели загружаются и работают корректно
- ✅ API возвращает реальные предсказания
- ✅ Фронтенд успешно интегрирован с бэкендом
- ✅ Время ответа < 1 секунды для одного предсказания
- ✅ Поддержка CORS для локальной разработки
- ✅ Обработка ошибок на всех уровнях

## Следующие шаги после Capstone 3

- Интеграция BERT и DistilBERT моделей
- Оптимизация через ONNX для браузера
- Добавление батч-обработки
- Кэширование предсказаний
- Мониторинг и логирование

