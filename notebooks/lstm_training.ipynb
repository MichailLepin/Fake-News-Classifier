{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LSTM Model Training for Fake News Classification\n",
    "\n",
    "Этот ноутбук содержит код для обучения LSTM модели классификации фейковых новостей в Google Colab.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Установка зависимостей\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n",
    "!pip install transformers scikit-learn pandas numpy matplotlib seaborn tqdm\n",
    "!pip install gensim\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Импорты\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "from collections import Counter\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Проверка GPU\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Using device: {device}')\n",
    "if torch.cuda.is_available():\n",
    "    print(f'GPU: {torch.cuda.get_device_name(0)}')\n",
    "    print(f'Memory: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.2f} GB')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ЗАГРУЗКА ДАННЫХ\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Установка Kaggle API\n",
    "!pip install kaggle\n",
    "\n",
    "# Загрузка датасета с Kaggle\n",
    "# ВАЖНО: Сначала загрузите ваш kaggle.json файл в Colab:\n",
    "# 1. Скачайте kaggle.json с https://www.kaggle.com/settings (Account -> API -> Create New Token)\n",
    "# 2. В Colab: Files -> Upload -> выберите kaggle.json\n",
    "# 3. Или используйте: from google.colab import files; files.upload()\n",
    "\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Настройка Kaggle API (если kaggle.json загружен)\n",
    "if os.path.exists('/content/kaggle.json'):\n",
    "    os.environ['KAGGLE_CONFIG_DIR'] = '/content'\n",
    "    !chmod 600 /content/kaggle.json\n",
    "\n",
    "# Загрузка датасета Fake and Real News\n",
    "!kaggle datasets download -d clmentbisaillon/fake-and-real-news-dataset -p /content --unzip\n",
    "\n",
    "# Загрузка данных\n",
    "fake_df = pd.read_csv('/content/Fake.csv')\n",
    "true_df = pd.read_csv('/content/True.csv')\n",
    "\n",
    "print(f\"✓ Fake news loaded: {fake_df.shape}\")\n",
    "print(f\"✓ True news loaded: {true_df.shape}\")\n",
    "\n",
    "# Объединение и подготовка данных\n",
    "fake_df['label'] = 'fake'\n",
    "true_df['label'] = 'real'\n",
    "\n",
    "# Используем колонку 'text' или 'title' в зависимости от структуры датасета\n",
    "if 'text' in fake_df.columns:\n",
    "    text_col = 'text'\n",
    "elif 'title' in fake_df.columns:\n",
    "    text_col = 'title'\n",
    "else:\n",
    "    text_col = fake_df.select_dtypes(include=['object']).columns[0]\n",
    "\n",
    "# Объединение\n",
    "combined_data = pd.concat([\n",
    "    fake_df[[text_col, 'label']].rename(columns={text_col: 'text'}),\n",
    "    true_df[[text_col, 'label']].rename(columns={text_col: 'text'})\n",
    "], ignore_index=True)\n",
    "\n",
    "# Очистка\n",
    "combined_data = combined_data[combined_data['text'].notna() & (combined_data['text'].str.len() > 0)]\n",
    "combined_data['label_binary'] = combined_data['label'].map({'fake': 1, 'real': 0})\n",
    "\n",
    "print(f\"\\nОбъединенный датасет: {combined_data.shape}\")\n",
    "print(f\"Распределение меток: {combined_data['label'].value_counts().to_dict()}\")\n",
    "\n",
    "# Разделение на train/val/test\n",
    "X = combined_data['text'].values\n",
    "y = combined_data['label_binary'].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_train, y_train, test_size=0.2, random_state=42, stratify=y_train\n",
    ")\n",
    "\n",
    "print(f\"\\nTrain: {len(X_train)}, Validation: {len(X_val)}, Test: {len(X_test)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# СОЗДАНИЕ СЛОВАРЯ И ТОКЕНИЗАЦИЯ\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "2):\n",
    "    \"\"\"Создание словаря из текстов\"\"\"\n",
    "    word_counts = Counter()\n",
    "    for text in texts:\n",
    "        words = str(text).lower().split()\n",
    "        word_counts.update(words)\n",
    "    \n",
    "    vocab = {'<PAD>': 0, '<UNK>': 1}\n",
    "    idx = 2\n",
    "    \n",
    "    for word, count in word_counts.items():\n",
    "        if count >= min_freq:\n",
    "            vocab[word] = idx\n",
    "            idx += 1\n",
    "    \n",
    "    return vocab\n",
    "\n",
    "def text_to_sequence(text, vocab, max_len=256):\n",
    "    \"\"\"Преобразование текста в последовательность индексов\"\"\"\n",
    "    words = str(text).lower().split()\n",
    "    sequence = [vocab.get(word, vocab['<UNK>']) for word in words[:max_len]]\n",
    "    \n",
    "    if len(sequence) < max_len:\n",
    "        sequence.extend([vocab['<PAD>']] * (max_len - len(sequence)))\n",
    "    \n",
    "    return sequence[:max_len]\n",
    "\n",
    "# Создание словаря\n",
    "print(\"\\nСоздание словаря...\")\n",
    "vocab = build_vocab(X_train, min_freq=2)\n",
    "vocab_size = len(vocab)\n",
    "print(f\"Размер словаря: {vocab_size}\")\n",
    "\n",
    "MAX_LEN = 256\n",
    "EMBEDDING_DIM = 100\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ЗАГРУЗКА GLOVE EMBEDDINGS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "100):\n",
    "    \"\"\"Загрузка предобученных GloVe embeddings\"\"\"\n",
    "    print(f\"Загрузка GloVe embeddings из {glove_path}...\")\n",
    "    \n",
    "    if not os.path.exists(glove_path):\n",
    "        print(\"Скачивание GloVe 6B.100d...\")\n",
    "        os.system('wget http://nlp.stanford.edu/data/glove.6B.zip')\n",
    "        os.system('unzip -q glove.6B.zip')\n",
    "    \n",
    "    embeddings_index = {}\n",
    "    with open(glove_path, 'r', encoding='utf-8') as f:\n",
    "        for line in tqdm(f, desc=\"Loading GloVe\"):\n",
    "            values = line.split()\n",
    "            word = values[0]\n",
    "            coefs = np.asarray(values[1:], dtype='float32')\n",
    "            embeddings_index[word] = coefs\n",
    "    \n",
    "    embedding_matrix = np.zeros((vocab_size, embedding_dim))\n",
    "    found = 0\n",
    "    \n",
    "    for word, idx in vocab.items():\n",
    "        if word in embeddings_index:\n",
    "            embedding_matrix[idx] = embeddings_index[word]\n",
    "            found += 1\n",
    "        else:\n",
    "            embedding_matrix[idx] = np.random.normal(scale=0.6, size=(embedding_dim,))\n",
    "    \n",
    "    print(f\"Найдено embeddings для {found}/{vocab_size} слов ({found/vocab_size*100:.2f}%)\")\n",
    "    return embedding_matrix\n",
    "\n",
    "GLOVE_PATH = 'glove.6B.100d.txt'\n",
    "try:\n",
    "    embedding_matrix = load_glove_embeddings(GLOVE_PATH, vocab, EMBEDDING_DIM)\n",
    "    use_pretrained = True\n",
    "except Exception as e:\n",
    "    print(f\"⚠ Не удалось загрузить GloVe: {e}\")\n",
    "    print(\"Используем случайную инициализацию\")\n",
    "    embedding_matrix = None\n",
    "    use_pretrained = False\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PYTORCH DATASET\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NewsDataset(Dataset):\n",
    "    def __init__(self, texts, labels, vocab, max_len=256):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.vocab = vocab\n",
    "        self.max_len = max_len\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        text = self.texts[idx]\n",
    "        label = self.labels[idx]\n",
    "        sequence = text_to_sequence(text, self.vocab, self.max_len)\n",
    "        return torch.LongTensor(sequence), torch.LongTensor([label])\n",
    "\n",
    "train_dataset = NewsDataset(X_train, y_train, vocab, MAX_LEN)\n",
    "val_dataset = NewsDataset(X_val, y_val, vocab, MAX_LEN)\n",
    "test_dataset = NewsDataset(X_test, y_test, vocab, MAX_LEN)\n",
    "\n",
    "BATCH_SIZE = 16\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LSTM МОДЕЛЬ\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim=128, num_layers=1, \n",
    "                 dropout=0.3, num_classes=2, embedding_matrix=None):\n",
    "        super(LSTMModel, self).__init__()\n",
    "        \n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        \n",
    "        if embedding_matrix is not None:\n",
    "            self.embedding.weight.data.copy_(torch.from_numpy(embedding_matrix))\n",
    "            self.embedding.weight.requires_grad = True\n",
    "        \n",
    "        self.lstm = nn.LSTM(\n",
    "            embedding_dim, \n",
    "            hidden_dim, \n",
    "            num_layers=num_layers,\n",
    "            batch_first=True,\n",
    "            bidirectional=True,\n",
    "            dropout=dropout if num_layers > 1 else 0\n",
    "        )\n",
    "        \n",
    "        self.fc = nn.Linear(hidden_dim * 2, num_classes)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        embedded = self.embedding(x)\n",
    "        lstm_out, (hidden, cell) = self.lstm(embedded)\n",
    "        output = torch.cat((hidden[-2], hidden[-1]), dim=1)\n",
    "        output = self.dropout(output)\n",
    "        output = self.fc(output)\n",
    "        return output\n",
    "\n",
    "lstm_model = LSTMModel(\n",
    "    vocab_size=vocab_size,\n",
    "    embedding_dim=EMBEDDING_DIM,\n",
    "    hidden_dim=128,\n",
    "    num_layers=1,\n",
    "    dropout=0.3,\n",
    "    num_classes=2,\n",
    "    embedding_matrix=embedding_matrix if use_pretrained else None\n",
    ").to(device)\n",
    "\n",
    "print(f\"\\nLSTM Model Parameters: {sum(p.numel() for p in lstm_model.parameters()):,}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ФУНКЦИИ ОБУЧЕНИЯ\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, train_loader, criterion, optimizer, device):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    for sequences, labels in tqdm(train_loader, desc=\"Training\"):\n",
    "        sequences = sequences.to(device)\n",
    "        labels = labels.squeeze().to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(sequences)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        \n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "    \n",
    "    return total_loss / len(train_loader), 100 * correct / total\n",
    "\n",
    "def evaluate(model, val_loader, criterion, device):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for sequences, labels in tqdm(val_loader, desc=\"Evaluating\"):\n",
    "            sequences = sequences.to(device)\n",
    "            labels = labels.squeeze().to(device)\n",
    "            \n",
    "            outputs = model(sequences)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            \n",
    "            all_preds.extend(predicted.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "    \n",
    "    avg_loss = total_loss / len(val_loader)\n",
    "    accuracy = accuracy_score(all_labels, all_preds)\n",
    "    f1 = f1_score(all_labels, all_preds, average='weighted')\n",
    "    \n",
    "    return avg_loss, accuracy, f1, all_preds, all_labels\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ОБУЧЕНИЕ\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\" * 60)\n",
    "print(\"ОБУЧЕНИЕ LSTM МОДЕЛИ\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(lstm_model.parameters(), lr=2e-5)\n",
    "\n",
    "num_epochs = 10\n",
    "best_f1 = 0\n",
    "patience = 3\n",
    "patience_counter = 0\n",
    "\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "train_accs = []\n",
    "val_accs = []\n",
    "val_f1s = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    print(f\"\\nEpoch {epoch+1}/{num_epochs}\")\n",
    "    \n",
    "    train_loss, train_acc = train_epoch(lstm_model, train_loader, criterion, optimizer, device)\n",
    "    val_loss, val_acc, val_f1, _, _ = evaluate(lstm_model, val_loader, criterion, device)\n",
    "    \n",
    "    train_losses.append(train_loss)\n",
    "    val_losses.append(val_loss)\n",
    "    train_accs.append(train_acc)\n",
    "    val_accs.append(val_acc)\n",
    "    val_f1s.append(val_f1)\n",
    "    \n",
    "    print(f\"Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.2f}%\")\n",
    "    print(f\"Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.2f}%, Val F1: {val_f1:.4f}\")\n",
    "    \n",
    "    if val_f1 > best_f1:\n",
    "        best_f1 = val_f1\n",
    "        patience_counter = 0\n",
    "        torch.save(lstm_model.state_dict(), 'best_lstm_model.pth')\n",
    "        print(f\"✓ New best F1: {best_f1:.4f}, model saved\")\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "        if patience_counter >= patience:\n",
    "            print(f\"Early stopping after {epoch+1} epochs\")\n",
    "            break\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(f\"Лучший F1 на валидации: {best_f1:.4f}\")\n",
    "print(\"=\" * 60)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ОЦЕНКА НА ТЕСТОВОМ НАБОРЕ\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_model.load_state_dict(torch.load('best_lstm_model.pth'))\n",
    "\n",
    "print(\"\\nОценка LSTM модели на тестовом наборе:\")\n",
    "test_loss, test_acc, test_f1, test_preds, test_labels = evaluate(\n",
    "    lstm_model, test_loader, criterion, device\n",
    ")\n",
    "\n",
    "print(f\"\\nTest Results:\")\n",
    "print(f\"  Loss: {test_loss:.4f}\")\n",
    "print(f\"  Accuracy: {test_acc:.4f}\")\n",
    "print(f\"  F1-Score: {test_f1:.4f}\")\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(test_labels, test_preds, target_names=['Real', 'Fake']))\n",
    "\n",
    "# Confusion Matrix\n",
    "cm = confusion_matrix(test_labels, test_preds)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=['Real', 'Fake'], yticklabels=['Real', 'Fake'])\n",
    "plt.title('LSTM - Confusion Matrix')\n",
    "plt.ylabel('True Label')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.show()\n",
    "\n",
    "lstm_results = {\n",
    "    'test_loss': float(test_loss),\n",
    "    'test_accuracy': float(test_acc),\n",
    "    'test_f1': float(test_f1),\n",
    "    'test_precision': float(precision_score(test_labels, test_preds, average='weighted')),\n",
    "    'test_recall': float(recall_score(test_labels, test_preds, average='weighted'))\n",
    "}\n",
    "\n",
    "print(f\"\\nLSTM Results: {lstm_results}\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
