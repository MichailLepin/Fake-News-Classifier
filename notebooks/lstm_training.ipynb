{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM Model Training for Fake News Classification\n",
    "\n",
    "This notebook contains code for training an LSTM model for fake news classification in Google Colab.\n",
    "\n",
    "## Notebook Structure\n",
    "\n",
    "1. **Install Dependencies** - Install required libraries\n",
    "2. **Imports** - Import all necessary modules\n",
    "3. **Load and Process Data** - Load ISOT/Kaggle dataset and preprocessing\n",
    "4. **Build Vocabulary and Tokenization** - Build vocabulary and convert text to sequences\n",
    "5. **Load GloVe Embeddings** - Load pre-trained word embeddings\n",
    "6. **PyTorch Dataset** - Create datasets for training\n",
    "7. **LSTM Model** - Define bidirectional LSTM architecture\n",
    "8. **Training Functions** - Functions for training and evaluating the model\n",
    "9. **Training** - Model training process\n",
    "10. **Test Set Evaluation** - Final model evaluation\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install Dependencies\n",
    "\n",
    "Install all required libraries for PyTorch, data processing, and visualization.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n",
    "!pip install scikit-learn pandas numpy matplotlib seaborn tqdm\n",
    "!pip install kagglehub\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports\n",
    "\n",
    "Import all necessary libraries and modules for data processing, models, and metrics.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "from collections import Counter\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Проверка GPU\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Using device: {device}')\n",
    "if torch.cuda.is_available():\n",
    "    print(f'GPU: {torch.cuda.get_device_name(0)}')\n",
    "    print(f'Memory: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.2f} GB')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and Process Data\n",
    "\n",
    "Load ISOT/Kaggle dataset from Kaggle and perform preprocessing:\n",
    "- Load Fake.csv and True.csv via kagglehub\n",
    "- Text cleaning (lowercase, URL removal, whitespace normalization)\n",
    "- Create binary labels\n",
    "- Stratified train/validation/test split (64%/16%/20%)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import kagglehub\n",
    "\n",
    "# Download dataset via kagglehub (no API keys required)\n",
    "path = kagglehub.dataset_download(\"clmentbisaillon/fake-and-real-news-dataset\")\n",
    "\n",
    "# Load data\n",
    "fake_df = pd.read_csv(f\"{path}/Fake.csv\")\n",
    "true_df = pd.read_csv(f\"{path}/True.csv\")\n",
    "\n",
    "print(f\"✓ Fake news loaded: {fake_df.shape}\")\n",
    "print(f\"✓ True news loaded: {true_df.shape}\")\n",
    "\n",
    "# Text cleaning function (from analyze_and_integrate.py script)\n",
    "def clean_text(text):\n",
    "    \"\"\"Clean text: lowercase, remove URLs, normalize whitespace\"\"\"\n",
    "    if pd.isna(text):\n",
    "        return \"\"\n",
    "    text = str(text)\n",
    "    # Convert to lowercase\n",
    "    text = text.lower()\n",
    "    # Remove URLs\n",
    "    text = re.sub(r'http\\S+|www\\S+|https\\S+', '', text, flags=re.MULTILINE)\n",
    "    # Remove extra whitespace\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    text = text.strip()\n",
    "    return text\n",
    "\n",
    "# Identify text column\n",
    "text_col = None\n",
    "for col in fake_df.columns:\n",
    "    if fake_df[col].dtype == 'object' and col.lower() in ['text', 'title', 'article']:\n",
    "        text_col = col\n",
    "        break\n",
    "if text_col is None:\n",
    "    text_col = fake_df.select_dtypes(include=['object']).columns[0]\n",
    "\n",
    "print(f\"\\nUsing column: '{text_col}'\")\n",
    "\n",
    "# Add labels\n",
    "fake_df['label'] = 'fake'\n",
    "true_df['label'] = 'real'\n",
    "\n",
    "# Combine data\n",
    "combined_data = pd.concat([fake_df, true_df], ignore_index=True)\n",
    "\n",
    "# Clean text\n",
    "print(\"\\nCleaning text...\")\n",
    "combined_data['text_cleaned'] = combined_data[text_col].apply(clean_text)\n",
    "\n",
    "# Create binary labels\n",
    "combined_data['label_binary'] = combined_data['label'].map({'fake': 1, 'real': 0})\n",
    "\n",
    "# Remove empty texts\n",
    "combined_data = combined_data[\n",
    "    combined_data['text_cleaned'].notna() & \n",
    "    (combined_data['text_cleaned'].str.len() > 0)\n",
    "]\n",
    "\n",
    "print(f\"\\nCombined dataset: {combined_data.shape}\")\n",
    "print(f\"Label distribution: {combined_data['label'].value_counts().to_dict()}\")\n",
    "\n",
    "# Split into train/val/test with stratification\n",
    "X = combined_data['text_cleaned'].values\n",
    "y = combined_data['label_binary'].values\n",
    "\n",
    "# First split: train+val (80%) and test (20%)\n",
    "X_train_val, X_test, y_train_val, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# Second split: train (64%) and val (16%)\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_train_val, y_train_val, test_size=0.2, random_state=42, stratify=y_train_val\n",
    ")\n",
    "\n",
    "print(f\"\\nData split:\")\n",
    "print(f\"  Train: {len(X_train):,} ({len(X_train)/len(combined_data)*100:.1f}%)\")\n",
    "print(f\"  Validation: {len(X_val):,} ({len(X_val)/len(combined_data)*100:.1f}%)\")\n",
    "print(f\"  Test: {len(X_test):,} ({len(X_test)/len(combined_data)*100:.1f}%)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Vocabulary and Tokenization\n",
    "\n",
    "Build vocabulary from training data and functions to convert text to index sequences.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_vocab(texts, min_freq=2):\n",
    "    \"\"\"Build vocabulary from texts\"\"\"\n",
    "    word_counts = Counter()\n",
    "    for text in texts:\n",
    "        words = str(text).lower().split()\n",
    "        word_counts.update(words)\n",
    "    \n",
    "    vocab = {'<PAD>': 0, '<UNK>': 1}\n",
    "    idx = 2\n",
    "    \n",
    "    for word, count in word_counts.items():\n",
    "        if count >= min_freq:\n",
    "            vocab[word] = idx\n",
    "            idx += 1\n",
    "    \n",
    "    return vocab\n",
    "\n",
    "def text_to_sequence(text, vocab, max_len=256):\n",
    "    \"\"\"Convert text to sequence of indices\"\"\"\n",
    "    words = str(text).lower().split()\n",
    "    sequence = [vocab.get(word, vocab['<UNK>']) for word in words[:max_len]]\n",
    "    \n",
    "    if len(sequence) < max_len:\n",
    "        sequence.extend([vocab['<PAD>']] * (max_len - len(sequence)))\n",
    "    \n",
    "    return sequence[:max_len]\n",
    "\n",
    "# Build vocabulary\n",
    "print(\"\\nBuilding vocabulary...\")\n",
    "vocab = build_vocab(X_train, min_freq=2)\n",
    "vocab_size = len(vocab)\n",
    "print(f\"Vocabulary size: {vocab_size}\")\n",
    "\n",
    "# Model parameters\n",
    "MAX_LEN = 256\n",
    "EMBEDDING_DIM = 100\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load GloVe Embeddings\n",
    "\n",
    "Load pre-trained GloVe embeddings (GloVe 6B.100d) to initialize the model's embedding layer.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_glove_embeddings(glove_path, vocab, embedding_dim=100):\n",
    "    \"\"\"Load pre-trained GloVe embeddings\"\"\"\n",
    "    print(f\"Loading GloVe embeddings from {glove_path}...\")\n",
    "    \n",
    "    if not os.path.exists(glove_path):\n",
    "        print(\"Downloading GloVe 6B.100d...\")\n",
    "        !wget -q http://nlp.stanford.edu/data/glove.6B.zip\n",
    "        !unzip -q glove.6B.zip\n",
    "    \n",
    "    embeddings_index = {}\n",
    "    with open(glove_path, 'r', encoding='utf-8') as f:\n",
    "        for line in tqdm(f, desc=\"Loading GloVe\"):\n",
    "            values = line.split()\n",
    "            word = values[0]\n",
    "            coefs = np.asarray(values[1:], dtype='float32')\n",
    "            embeddings_index[word] = coefs\n",
    "    \n",
    "    embedding_matrix = np.zeros((vocab_size, embedding_dim))\n",
    "    found = 0\n",
    "    \n",
    "    for word, idx in vocab.items():\n",
    "        if word in embeddings_index:\n",
    "            embedding_matrix[idx] = embeddings_index[word]\n",
    "            found += 1\n",
    "        else:\n",
    "            # Random initialization for unknown words\n",
    "            embedding_matrix[idx] = np.random.normal(scale=0.6, size=(embedding_dim,))\n",
    "    \n",
    "    print(f\"Found embeddings for {found}/{vocab_size} words ({found/vocab_size*100:.2f}%)\")\n",
    "    return embedding_matrix\n",
    "\n",
    "# Load GloVe embeddings\n",
    "GLOVE_PATH = 'glove.6B.100d.txt'\n",
    "try:\n",
    "    embedding_matrix = load_glove_embeddings(GLOVE_PATH, vocab, EMBEDDING_DIM)\n",
    "    use_pretrained = True\n",
    "except Exception as e:\n",
    "    print(f\"⚠ Failed to load GloVe: {e}\")\n",
    "    print(\"Using random initialization\")\n",
    "    embedding_matrix = None\n",
    "    use_pretrained = False\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PyTorch Dataset\n",
    "\n",
    "Create Dataset and DataLoader classes for efficient data loading during training.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NewsDataset(Dataset):\n",
    "    def __init__(self, texts, labels, vocab, max_len=256):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.vocab = vocab\n",
    "        self.max_len = max_len\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        text = self.texts[idx]\n",
    "        label = self.labels[idx]\n",
    "        sequence = text_to_sequence(text, self.vocab, self.max_len)\n",
    "        return torch.LongTensor(sequence), torch.LongTensor([label])\n",
    "\n",
    "train_dataset = NewsDataset(X_train, y_train, vocab, MAX_LEN)\n",
    "val_dataset = NewsDataset(X_val, y_val, vocab, MAX_LEN)\n",
    "test_dataset = NewsDataset(X_test, y_test, vocab, MAX_LEN)\n",
    "\n",
    "BATCH_SIZE = 16\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM Model\n",
    "\n",
    "Define bidirectional LSTM model architecture for processing text sequences.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim=128, num_layers=1, \n",
    "                 dropout=0.3, num_classes=2, embedding_matrix=None):\n",
    "        super(LSTMModel, self).__init__()\n",
    "        \n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        \n",
    "        if embedding_matrix is not None:\n",
    "            self.embedding.weight.data.copy_(torch.from_numpy(embedding_matrix))\n",
    "            self.embedding.weight.requires_grad = True\n",
    "        \n",
    "        self.lstm = nn.LSTM(\n",
    "            embedding_dim, \n",
    "            hidden_dim, \n",
    "            num_layers=num_layers,\n",
    "            batch_first=True,\n",
    "            bidirectional=True,\n",
    "            dropout=dropout if num_layers > 1 else 0\n",
    "        )\n",
    "        \n",
    "        self.fc = nn.Linear(hidden_dim * 2, num_classes)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        embedded = self.embedding(x)\n",
    "        lstm_out, (hidden, cell) = self.lstm(embedded)\n",
    "        output = torch.cat((hidden[-2], hidden[-1]), dim=1)\n",
    "        output = self.dropout(output)\n",
    "        output = self.fc(output)\n",
    "        return output\n",
    "\n",
    "lstm_model = LSTMModel(\n",
    "    vocab_size=vocab_size,\n",
    "    embedding_dim=EMBEDDING_DIM,\n",
    "    hidden_dim=128,\n",
    "    num_layers=1,\n",
    "    dropout=0.3,\n",
    "    num_classes=2,\n",
    "    embedding_matrix=embedding_matrix if use_pretrained else None\n",
    ").to(device)\n",
    "\n",
    "print(f\"\\nLSTM Model Parameters: {sum(p.numel() for p in lstm_model.parameters()):,}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Functions\n",
    "\n",
    "Functions for training the model for one epoch and evaluating the model on the validation set.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, train_loader, criterion, optimizer, device):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    for sequences, labels in tqdm(train_loader, desc=\"Training\"):\n",
    "        sequences = sequences.to(device)\n",
    "        labels = labels.squeeze().to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(sequences)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        \n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "    \n",
    "    return total_loss / len(train_loader), 100 * correct / total\n",
    "\n",
    "def evaluate(model, val_loader, criterion, device):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for sequences, labels in tqdm(val_loader, desc=\"Evaluating\"):\n",
    "            sequences = sequences.to(device)\n",
    "            labels = labels.squeeze().to(device)\n",
    "            \n",
    "            outputs = model(sequences)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            \n",
    "            all_preds.extend(predicted.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "    \n",
    "    avg_loss = total_loss / len(val_loader)\n",
    "    accuracy = accuracy_score(all_labels, all_preds)\n",
    "    f1 = f1_score(all_labels, all_preds, average='weighted')\n",
    "    \n",
    "    return avg_loss, accuracy, f1, all_preds, all_labels\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "\n",
    "LSTM model training process with early stopping based on F1-score on the validation set.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"TRAINING LSTM MODEL\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(lstm_model.parameters(), lr=2e-5)\n",
    "\n",
    "num_epochs = 10\n",
    "best_f1 = 0\n",
    "patience = 3\n",
    "patience_counter = 0\n",
    "\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "train_accs = []\n",
    "val_accs = []\n",
    "val_f1s = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    print(f\"\\nEpoch {epoch+1}/{num_epochs}\")\n",
    "    \n",
    "    train_loss, train_acc = train_epoch(lstm_model, train_loader, criterion, optimizer, device)\n",
    "    val_loss, val_acc, val_f1, _, _ = evaluate(lstm_model, val_loader, criterion, device)\n",
    "    \n",
    "    train_losses.append(train_loss)\n",
    "    val_losses.append(val_loss)\n",
    "    train_accs.append(train_acc)\n",
    "    val_accs.append(val_acc)\n",
    "    val_f1s.append(val_f1)\n",
    "    \n",
    "    print(f\"Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.2f}%\")\n",
    "    print(f\"Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.2f}%, Val F1: {val_f1:.4f}\")\n",
    "    \n",
    "    if val_f1 > best_f1:\n",
    "        best_f1 = val_f1\n",
    "        patience_counter = 0\n",
    "        torch.save(lstm_model.state_dict(), 'best_lstm_model.pth')\n",
    "        print(f\"✓ New best F1: {best_f1:.4f}, model saved\")\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "        if patience_counter >= patience:\n",
    "            print(f\"Early stopping after {epoch+1} epochs\")\n",
    "            break\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(f\"Best validation F1: {best_f1:.4f}\")\n",
    "print(\"=\" * 60)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Set Evaluation\n",
    "\n",
    "Final model evaluation on the test set with metrics (accuracy, F1-score, precision, recall) and confusion matrix.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_model.load_state_dict(torch.load('best_lstm_model.pth'))\n",
    "\n",
    "print(\"\\nEvaluating LSTM model on test set:\")\n",
    "test_loss, test_acc, test_f1, test_preds, test_labels = evaluate(\n",
    "    lstm_model, test_loader, criterion, device\n",
    ")\n",
    "\n",
    "print(f\"\\nTest Results:\")\n",
    "print(f\"  Loss: {test_loss:.4f}\")\n",
    "print(f\"  Accuracy: {test_acc:.4f}\")\n",
    "print(f\"  F1-Score: {test_f1:.4f}\")\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(test_labels, test_preds, target_names=['Real', 'Fake']))\n",
    "\n",
    "# Confusion Matrix\n",
    "cm = confusion_matrix(test_labels, test_preds)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=['Real', 'Fake'], yticklabels=['Real', 'Fake'])\n",
    "plt.title('LSTM - Confusion Matrix')\n",
    "plt.ylabel('True Label')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.show()\n",
    "\n",
    "lstm_results = {\n",
    "    'test_loss': float(test_loss),\n",
    "    'test_accuracy': float(test_acc),\n",
    "    'test_f1': float(test_f1),\n",
    "    'test_precision': float(precision_score(test_labels, test_preds, average='weighted')),\n",
    "    'test_recall': float(recall_score(test_labels, test_preds, average='weighted'))\n",
    "}\n",
    "\n",
    "print(f\"\\nLSTM Results: {lstm_results}\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
