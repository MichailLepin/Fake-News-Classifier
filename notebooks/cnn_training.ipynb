{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MichailLepin/Fake-News-Classifier/blob/main/notebooks/cnn_training.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CvTvrrGpc4X6"
      },
      "source": [
        "# CNN Model Training for Fake News Classification\n",
        "\n",
        "This notebook contains code for training a CNN model for fake news classification in Google Colab.\n",
        "\n",
        "## Notebook Structure\n",
        "\n",
        "1. **Install Dependencies** - Install required libraries\n",
        "2. **Imports** - Import all necessary modules\n",
        "3. **Load and Process Data** - Load ISOT/Kaggle dataset and preprocessing\n",
        "4. **Build Vocabulary and Tokenization** - Build vocabulary and convert text to sequences\n",
        "5. **Load GloVe Embeddings** - Load pre-trained word embeddings\n",
        "6. **PyTorch Dataset** - Create datasets for training\n",
        "7. **CNN Model** - Define CNN architecture\n",
        "8. **Training Functions** - Functions for training and evaluating the model\n",
        "9. **Training** - Model training process\n",
        "10. **Test Set Evaluation** - Final model evaluation\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J2JzPBPpc4X6"
      },
      "source": [
        "## Install Dependencies\n",
        "\n",
        "Install all required libraries for PyTorch, data processing, and visualization.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OYbNfzxLc4X7",
        "outputId": "ca6abdd1-7c0f-4efd-e908-8d5df1eec23c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://download.pytorch.org/whl/cu118\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.9.0+cpu)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.12/dist-packages (0.24.0+cpu)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.12/dist-packages (2.9.0+cpu)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch) (3.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch) (2025.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from torchvision) (2.0.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from torchvision) (11.3.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.3)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (1.6.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (2.0.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (3.10.0)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.12/dist-packages (0.13.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (4.67.1)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.16.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (4.61.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (3.2.5)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: kagglehub in /usr/local/lib/python3.12/dist-packages (0.3.13)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from kagglehub) (25.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.12/dist-packages (from kagglehub) (6.0.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from kagglehub) (2.32.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from kagglehub) (4.67.1)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->kagglehub) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->kagglehub) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->kagglehub) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->kagglehub) (2025.11.12)\n"
          ]
        }
      ],
      "source": [
        "!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n",
        "!pip install scikit-learn pandas numpy matplotlib seaborn tqdm\n",
        "!pip install kagglehub\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z6QoQDDxc4X7"
      },
      "source": [
        "## Imports\n",
        "\n",
        "Import all necessary libraries and modules for data processing, models, and metrics.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ecliYDCQc4X7",
        "outputId": "7a0151d8-eb6b-41f4-cbe5-eb00bb774560"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cpu\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from tqdm import tqdm\n",
        "from collections import Counter\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Проверка GPU\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f'Using device: {device}')\n",
        "if torch.cuda.is_available():\n",
        "    print(f'GPU: {torch.cuda.get_device_name(0)}')\n",
        "    print(f'Memory: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.2f} GB')\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LrzA0KxLc4X7"
      },
      "source": [
        "## Load and Process Data\n",
        "\n",
        "Load ISOT/Kaggle dataset from Kaggle and perform preprocessing:\n",
        "- Load Fake.csv and True.csv via kagglehub\n",
        "- Text cleaning (lowercase, URL removal, whitespace normalization)\n",
        "- Create binary labels\n",
        "- Stratified train/validation/test split (64%/16%/20%)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "skZLjbWhc4X8",
        "outputId": "5e02a947-19fa-4646-d16c-64fb402c23ff"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using Colab cache for faster access to the 'fake-and-real-news-dataset' dataset.\n",
            "✓ Fake news loaded: (23481, 4)\n",
            "✓ True news loaded: (21417, 4)\n",
            "\n",
            "Using column: 'title'\n",
            "\n",
            "Cleaning text...\n",
            "\n",
            "Combined dataset: (44889, 7)\n",
            "Label distribution: {'fake': 23472, 'real': 21417}\n",
            "\n",
            "Data split:\n",
            "  Train: 28,728 (64.0%)\n",
            "  Validation: 7,183 (16.0%)\n",
            "  Test: 8,978 (20.0%)\n"
          ]
        }
      ],
      "source": [
        "import re\n",
        "import kagglehub\n",
        "\n",
        "# Download dataset via kagglehub (no API keys required)\n",
        "path = kagglehub.dataset_download(\"clmentbisaillon/fake-and-real-news-dataset\")\n",
        "\n",
        "# Load data\n",
        "fake_df = pd.read_csv(f\"{path}/Fake.csv\")\n",
        "true_df = pd.read_csv(f\"{path}/True.csv\")\n",
        "\n",
        "print(f\"✓ Fake news loaded: {fake_df.shape}\")\n",
        "print(f\"✓ True news loaded: {true_df.shape}\")\n",
        "\n",
        "# Text cleaning function (from analyze_and_integrate.py script)\n",
        "def clean_text(text):\n",
        "    \"\"\"Clean text: lowercase, remove URLs, normalize whitespace\"\"\"\n",
        "    if pd.isna(text):\n",
        "        return \"\"\n",
        "    text = str(text)\n",
        "    # Convert to lowercase\n",
        "    text = text.lower()\n",
        "    # Remove URLs\n",
        "    text = re.sub(r'http\\S+|www\\S+|https\\S+', '', text, flags=re.MULTILINE)\n",
        "    # Remove extra whitespace\n",
        "    text = re.sub(r'\\s+', ' ', text)\n",
        "    text = text.strip()\n",
        "    return text\n",
        "\n",
        "# Identify text column\n",
        "text_col = None\n",
        "for col in fake_df.columns:\n",
        "    if fake_df[col].dtype == 'object' and col.lower() in ['text', 'title', 'article']:\n",
        "        text_col = col\n",
        "        break\n",
        "if text_col is None:\n",
        "    text_col = fake_df.select_dtypes(include=['object']).columns[0]\n",
        "\n",
        "print(f\"\\nUsing column: '{text_col}'\")\n",
        "\n",
        "# Add labels\n",
        "fake_df['label'] = 'fake'\n",
        "true_df['label'] = 'real'\n",
        "\n",
        "# Combine data\n",
        "combined_data = pd.concat([fake_df, true_df], ignore_index=True)\n",
        "\n",
        "# Clean text\n",
        "print(\"\\nCleaning text...\")\n",
        "combined_data['text_cleaned'] = combined_data[text_col].apply(clean_text)\n",
        "\n",
        "# Create binary labels\n",
        "combined_data['label_binary'] = combined_data['label'].map({'fake': 1, 'real': 0})\n",
        "\n",
        "# Remove empty texts\n",
        "combined_data = combined_data[\n",
        "    combined_data['text_cleaned'].notna() &\n",
        "    (combined_data['text_cleaned'].str.len() > 0)\n",
        "]\n",
        "\n",
        "print(f\"\\nCombined dataset: {combined_data.shape}\")\n",
        "print(f\"Label distribution: {combined_data['label'].value_counts().to_dict()}\")\n",
        "\n",
        "# Split into train/val/test with stratification\n",
        "X = combined_data['text_cleaned'].values\n",
        "y = combined_data['label_binary'].values\n",
        "\n",
        "# First split: train+val (80%) and test (20%)\n",
        "X_train_val, X_test, y_train_val, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "# Second split: train (64%) and val (16%)\n",
        "X_train, X_val, y_train, y_val = train_test_split(\n",
        "    X_train_val, y_train_val, test_size=0.2, random_state=42, stratify=y_train_val\n",
        ")\n",
        "\n",
        "print(f\"\\nData split:\")\n",
        "print(f\"  Train: {len(X_train):,} ({len(X_train)/len(combined_data)*100:.1f}%)\")\n",
        "print(f\"  Validation: {len(X_val):,} ({len(X_val)/len(combined_data)*100:.1f}%)\")\n",
        "print(f\"  Test: {len(X_test):,} ({len(X_test)/len(combined_data)*100:.1f}%)\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z-D1NcJYc4X8"
      },
      "source": [
        "## Build Vocabulary and Tokenization\n",
        "\n",
        "Build vocabulary from training data and functions to convert text to index sequences.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "auZaacC5c4X8",
        "outputId": "b786d843-9f2c-48aa-ead2-67691da1acff"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Building vocabulary...\n",
            "Vocabulary size: 18321\n"
          ]
        }
      ],
      "source": [
        "def build_vocab(texts, min_freq=2):\n",
        "    \"\"\"Build vocabulary from texts\"\"\"\n",
        "    word_counts = Counter()\n",
        "    for text in texts:\n",
        "        words = str(text).lower().split()\n",
        "        word_counts.update(words)\n",
        "\n",
        "    vocab = {'<PAD>': 0, '<UNK>': 1}\n",
        "    idx = 2\n",
        "\n",
        "    for word, count in word_counts.items():\n",
        "        if count >= min_freq:\n",
        "            vocab[word] = idx\n",
        "            idx += 1\n",
        "\n",
        "    return vocab\n",
        "\n",
        "def text_to_sequence(text, vocab, max_len=256):\n",
        "    \"\"\"Convert text to sequence of indices\"\"\"\n",
        "    words = str(text).lower().split()\n",
        "    sequence = [vocab.get(word, vocab['<UNK>']) for word in words[:max_len]]\n",
        "\n",
        "    if len(sequence) < max_len:\n",
        "        sequence.extend([vocab['<PAD>']] * (max_len - len(sequence)))\n",
        "\n",
        "    return sequence[:max_len]\n",
        "\n",
        "# Build vocabulary\n",
        "print(\"\\nBuilding vocabulary...\")\n",
        "vocab = build_vocab(X_train, min_freq=2)\n",
        "vocab_size = len(vocab)\n",
        "print(f\"Vocabulary size: {vocab_size}\")\n",
        "\n",
        "# Model parameters\n",
        "MAX_LEN = 256\n",
        "EMBEDDING_DIM = 100\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YHHDFZdFasc_"
      },
      "source": [
        "## Save Vocabulary\n",
        "\n",
        "Save the vocabulary to a JSON file for use in the backend API."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "svgURFGRasc_",
        "outputId": "4d2edd83-1b5e-4a5d-c8f5-05969af9dc56",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✓ Vocab found! Size: 18321\n",
            "✓ Vocab saved to vocab/vocab.json\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_f4ab9bd5-052d-4855-a4c6-45365a198e6d\", \"vocab.json\", 366641)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "✓ FILE DOWNLOADED!\n",
            "============================================================\n",
            "\n",
            "Next steps:\n",
            "1. The vocab.json file should be downloaded to your Downloads folder\n",
            "2. Copy it to the vocab/ folder in your project\n",
            "3. The path should be: Fake-News-Classifier-2/vocab/vocab.json\n",
            "\n",
            "Vocab structure check:\n",
            "  - <PAD>: 0\n",
            "  - <UNK>: 1\n",
            "  - Total words: 18321\n"
          ]
        }
      ],
      "source": [
        "# Save vocabulary for backend use\n",
        "import json\n",
        "import os\n",
        "from google.colab import files\n",
        "\n",
        "# Check if vocab exists - try multiple ways to find it\n",
        "vocab_found = False\n",
        "vocab_to_save = None\n",
        "\n",
        "# Method 1: Check globals\n",
        "if 'vocab' in globals():\n",
        "    vocab_to_save = globals()['vocab']\n",
        "    vocab_found = True\n",
        "# Method 2: Check if vocab_size exists and try to rebuild\n",
        "elif 'vocab_size' in globals() and 'X_train' in globals():\n",
        "    print(\"⚠ Vocab variable not found, but vocab_size exists.\")\n",
        "    print(\"Attempting to rebuild vocabulary from training data...\")\n",
        "    from collections import Counter\n",
        "\n",
        "    def build_vocab(texts, min_freq=2):\n",
        "        \"\"\"Build vocabulary from texts\"\"\"\n",
        "        word_counts = Counter()\n",
        "        for text in texts:\n",
        "            words = str(text).lower().split()\n",
        "            word_counts.update(words)\n",
        "        vocab = {'<PAD>': 0, '<UNK>': 1}\n",
        "        idx = 2\n",
        "        for word, count in word_counts.items():\n",
        "            if count >= min_freq:\n",
        "                vocab[word] = idx\n",
        "                idx += 1\n",
        "        return vocab\n",
        "\n",
        "    vocab_to_save = build_vocab(X_train, min_freq=2)\n",
        "    vocab_found = True\n",
        "    print(f\"✓ Vocabulary rebuilt! Size: {len(vocab_to_save)}\")\n",
        "else:\n",
        "    print(\"❌ ERROR: Vocabulary not found!\")\n",
        "    print(\"\\nTo fix this:\")\n",
        "    print(\"1. Make sure you have executed the 'Build Vocabulary and Tokenization' cell (Cell 9)\")\n",
        "    print(\"2. The cell should create a variable called 'vocab'\")\n",
        "    print(\"3. Check that the cell executed without errors\")\n",
        "    print(\"\\nIf the cell was executed, try running it again.\")\n",
        "    raise NameError(\"Variable 'vocab' not found. Please execute the 'Build Vocabulary and Tokenization' cell first.\")\n",
        "\n",
        "if vocab_found and vocab_to_save:\n",
        "    print(f\"✓ Vocab found! Size: {len(vocab_to_save)}\")\n",
        "\n",
        "    # Create directory\n",
        "    os.makedirs('vocab', exist_ok=True)\n",
        "\n",
        "    # Save vocab to JSON\n",
        "    vocab_path = 'vocab/vocab.json'\n",
        "    with open(vocab_path, 'w', encoding='utf-8') as f:\n",
        "        json.dump(vocab_to_save, f, ensure_ascii=False, indent=2)\n",
        "\n",
        "    print(f\"✓ Vocab saved to {vocab_path}\")\n",
        "\n",
        "    # Download the file\n",
        "    files.download(vocab_path)\n",
        "\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"✓ FILE DOWNLOADED!\")\n",
        "    print(\"=\"*60)\n",
        "    print(\"\\nNext steps:\")\n",
        "    print(\"1. The vocab.json file should be downloaded to your Downloads folder\")\n",
        "    print(\"2. Copy it to the vocab/ folder in your project\")\n",
        "    print(\"3. The path should be: Fake-News-Classifier-2/vocab/vocab.json\")\n",
        "    print(\"\\nVocab structure check:\")\n",
        "    print(f\"  - <PAD>: {vocab_to_save.get('<PAD>', 'NOT FOUND')}\")\n",
        "    print(f\"  - <UNK>: {vocab_to_save.get('<UNK>', 'NOT FOUND')}\")\n",
        "    print(f\"  - Total words: {len(vocab_to_save)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "iNi2l5psasdA",
        "outputId": "8d5b63d6-07a3-46e8-d7d0-a7599c32a338",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This cell is a duplicate. Please use Cell 11 above to save vocabulary.\n"
          ]
        }
      ],
      "source": [
        "# This is a duplicate cell - you can delete it or ignore it\n",
        "# Use the cell above (Cell 11) to save vocabulary\n",
        "print(\"This cell is a duplicate. Please use Cell 11 above to save vocabulary.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wx44Qi2fc4X8"
      },
      "source": [
        "## Load GloVe Embeddings\n",
        "\n",
        "Load pre-trained GloVe embeddings (GloVe 6B.100d) to initialize the model's embedding layer.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TCHbXQLXc4X8",
        "outputId": "468b3687-b52e-45d4-97e0-885f2d5e0641"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading GloVe embeddings from glove.6B.100d.txt...\n",
            "Downloading GloVe 6B.100d...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loading GloVe: 400000it [00:13, 30762.53it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found embeddings for 11316/18321 words (61.77%)\n"
          ]
        }
      ],
      "source": [
        "def load_glove_embeddings(glove_path, vocab, embedding_dim=100):\n",
        "    \"\"\"Load pre-trained GloVe embeddings\"\"\"\n",
        "    print(f\"Loading GloVe embeddings from {glove_path}...\")\n",
        "\n",
        "    if not os.path.exists(glove_path):\n",
        "        print(\"Downloading GloVe 6B.100d...\")\n",
        "        !wget -q http://nlp.stanford.edu/data/glove.6B.zip\n",
        "        !unzip -q glove.6B.zip\n",
        "\n",
        "    embeddings_index = {}\n",
        "    with open(glove_path, 'r', encoding='utf-8') as f:\n",
        "        for line in tqdm(f, desc=\"Loading GloVe\"):\n",
        "            values = line.split()\n",
        "            word = values[0]\n",
        "            coefs = np.asarray(values[1:], dtype='float32')\n",
        "            embeddings_index[word] = coefs\n",
        "\n",
        "    embedding_matrix = np.zeros((vocab_size, embedding_dim))\n",
        "    found = 0\n",
        "\n",
        "    for word, idx in vocab.items():\n",
        "        if word in embeddings_index:\n",
        "            embedding_matrix[idx] = embeddings_index[word]\n",
        "            found += 1\n",
        "        else:\n",
        "            # Random initialization for unknown words\n",
        "            embedding_matrix[idx] = np.random.normal(scale=0.6, size=(embedding_dim,))\n",
        "\n",
        "    print(f\"Found embeddings for {found}/{vocab_size} words ({found/vocab_size*100:.2f}%)\")\n",
        "    return embedding_matrix\n",
        "\n",
        "# Load GloVe embeddings\n",
        "GLOVE_PATH = 'glove.6B.100d.txt'\n",
        "try:\n",
        "    embedding_matrix = load_glove_embeddings(GLOVE_PATH, vocab, EMBEDDING_DIM)\n",
        "    use_pretrained = True\n",
        "except Exception as e:\n",
        "    print(f\"⚠ Failed to load GloVe: {e}\")\n",
        "    print(\"Using random initialization\")\n",
        "    embedding_matrix = None\n",
        "    use_pretrained = False\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fp2b3Qhbc4X9"
      },
      "source": [
        "## PyTorch Dataset\n",
        "\n",
        "Create Dataset and DataLoader classes for efficient data loading during training.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "9txqkQj3c4X9"
      },
      "outputs": [],
      "source": [
        "class NewsDataset(Dataset):\n",
        "    def __init__(self, texts, labels, vocab, max_len=256):\n",
        "        self.texts = texts\n",
        "        self.labels = labels\n",
        "        self.vocab = vocab\n",
        "        self.max_len = max_len\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.texts)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        text = self.texts[idx]\n",
        "        label = self.labels[idx]\n",
        "        sequence = text_to_sequence(text, self.vocab, self.max_len)\n",
        "        return torch.LongTensor(sequence), torch.LongTensor([label])\n",
        "\n",
        "train_dataset = NewsDataset(X_train, y_train, vocab, MAX_LEN)\n",
        "val_dataset = NewsDataset(X_val, y_val, vocab, MAX_LEN)\n",
        "test_dataset = NewsDataset(X_test, y_test, vocab, MAX_LEN)\n",
        "\n",
        "BATCH_SIZE = 16\n",
        "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
        "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cZejEfAcc4X9"
      },
      "source": [
        "## CNN Model\n",
        "\n",
        "Define CNN model architecture using convolutional layers with different filter sizes (3, 4, 5) to extract features from text.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xVjcuNyMc4X9",
        "outputId": "786a7192-7718-43d7-e374-746451f4e6ed"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "CNN Model Parameters: 1,953,002\n"
          ]
        }
      ],
      "source": [
        "class CNNModel(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim, num_filters=100,\n",
        "                 filter_sizes=[3, 4, 5], num_classes=2, dropout=0.3,\n",
        "                 embedding_matrix=None):\n",
        "        super(CNNModel, self).__init__()\n",
        "\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
        "\n",
        "        if embedding_matrix is not None:\n",
        "            self.embedding.weight.data.copy_(torch.from_numpy(embedding_matrix))\n",
        "            self.embedding.weight.requires_grad = True\n",
        "\n",
        "        # Convolutional layers with different filter sizes\n",
        "        self.convs = nn.ModuleList([\n",
        "            nn.Conv1d(embedding_dim, num_filters, kernel_size=fs)\n",
        "            for fs in filter_sizes\n",
        "        ])\n",
        "\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.fc = nn.Linear(len(filter_sizes) * num_filters, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x shape: (batch_size, seq_len)\n",
        "        embedded = self.embedding(x)  # (batch_size, seq_len, embedding_dim)\n",
        "\n",
        "        # Conv1d expects (batch_size, embedding_dim, seq_len)\n",
        "        embedded = embedded.permute(0, 2, 1)  # (batch_size, embedding_dim, seq_len)\n",
        "\n",
        "        # Apply convolutions and max pooling\n",
        "        conv_outputs = []\n",
        "        for conv in self.convs:\n",
        "            conv_out = conv(embedded)  # (batch_size, num_filters, seq_len - filter_size + 1)\n",
        "            conv_out = torch.relu(conv_out)\n",
        "            pooled = torch.max_pool1d(conv_out, kernel_size=conv_out.size(2))  # (batch_size, num_filters, 1)\n",
        "            pooled = pooled.squeeze(2)  # (batch_size, num_filters)\n",
        "            conv_outputs.append(pooled)\n",
        "\n",
        "        # Concatenate outputs from all convolutions\n",
        "        concatenated = torch.cat(conv_outputs, dim=1)  # (batch_size, len(filter_sizes) * num_filters)\n",
        "\n",
        "        concatenated = self.dropout(concatenated)\n",
        "        output = self.fc(concatenated)  # (batch_size, num_classes)\n",
        "\n",
        "        return output\n",
        "\n",
        "cnn_model = CNNModel(\n",
        "    vocab_size=vocab_size,\n",
        "    embedding_dim=EMBEDDING_DIM,\n",
        "    num_filters=100,\n",
        "    filter_sizes=[3, 4, 5],\n",
        "    num_classes=2,\n",
        "    dropout=0.3,\n",
        "    embedding_matrix=embedding_matrix if use_pretrained else None\n",
        ").to(device)\n",
        "\n",
        "print(f\"\\nCNN Model Parameters: {sum(p.numel() for p in cnn_model.parameters()):,}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9n0yRl7oc4X9"
      },
      "source": [
        "## Training Functions\n",
        "\n",
        "Functions for training the model for one epoch and evaluating the model on the validation set.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "6ZhfTNg1c4X9"
      },
      "outputs": [],
      "source": [
        "def train_epoch(model, train_loader, criterion, optimizer, device):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    for sequences, labels in tqdm(train_loader, desc=\"Training\"):\n",
        "        sequences = sequences.to(device)\n",
        "        labels = labels.squeeze().to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(sequences)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "    return total_loss / len(train_loader), 100 * correct / total\n",
        "\n",
        "def evaluate(model, val_loader, criterion, device):\n",
        "    model.eval()\n",
        "    total_loss = 0\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for sequences, labels in tqdm(val_loader, desc=\"Evaluating\"):\n",
        "            sequences = sequences.to(device)\n",
        "            labels = labels.squeeze().to(device)\n",
        "\n",
        "            outputs = model(sequences)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            total_loss += loss.item()\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "\n",
        "            all_preds.extend(predicted.cpu().numpy())\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "    avg_loss = total_loss / len(val_loader)\n",
        "    accuracy = accuracy_score(all_labels, all_preds)\n",
        "    f1 = f1_score(all_labels, all_preds, average='weighted')\n",
        "\n",
        "    return avg_loss, accuracy, f1, all_preds, all_labels\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0hpGaq2Jc4X9"
      },
      "source": [
        "## Training\n",
        "\n",
        "CNN model training process with early stopping based on F1-score on the validation set.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gmTlpGbgc4X9",
        "outputId": "4579857b-a3dd-4d07-c2fa-9727c687594f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "TRAINING CNN MODEL\n",
            "============================================================\n",
            "\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 1796/1796 [03:19<00:00,  8.98it/s]\n",
            "Evaluating: 100%|██████████| 449/449 [00:14<00:00, 30.52it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.4725, Train Acc: 81.30%\n",
            "Val Loss: 0.3223, Val Acc: 0.89%, Val F1: 0.8919\n",
            "✓ New best F1: 0.8919, model saved\n",
            "\n",
            "Epoch 2/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 1796/1796 [03:19<00:00,  9.01it/s]\n",
            "Evaluating: 100%|██████████| 449/449 [00:14<00:00, 30.51it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.2765, Train Acc: 89.78%\n",
            "Val Loss: 0.2418, Val Acc: 0.91%, Val F1: 0.9051\n",
            "✓ New best F1: 0.9051, model saved\n",
            "\n",
            "Epoch 3/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 1796/1796 [03:21<00:00,  8.90it/s]\n",
            "Evaluating: 100%|██████████| 449/449 [00:14<00:00, 30.66it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.2266, Train Acc: 91.11%\n",
            "Val Loss: 0.2135, Val Acc: 0.91%, Val F1: 0.9147\n",
            "✓ New best F1: 0.9147, model saved\n",
            "\n",
            "Epoch 4/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 1796/1796 [03:20<00:00,  8.95it/s]\n",
            "Evaluating: 100%|██████████| 449/449 [00:14<00:00, 30.08it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.2027, Train Acc: 91.95%\n",
            "Val Loss: 0.1975, Val Acc: 0.92%, Val F1: 0.9210\n",
            "✓ New best F1: 0.9210, model saved\n",
            "\n",
            "Epoch 5/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 1796/1796 [03:20<00:00,  8.98it/s]\n",
            "Evaluating: 100%|██████████| 449/449 [00:15<00:00, 29.62it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.1813, Train Acc: 92.97%\n",
            "Val Loss: 0.1802, Val Acc: 0.93%, Val F1: 0.9288\n",
            "✓ New best F1: 0.9288, model saved\n",
            "\n",
            "Epoch 6/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 1796/1796 [03:36<00:00,  8.30it/s]\n",
            "Evaluating: 100%|██████████| 449/449 [00:14<00:00, 30.52it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.1661, Train Acc: 93.55%\n",
            "Val Loss: 0.1690, Val Acc: 0.93%, Val F1: 0.9320\n",
            "✓ New best F1: 0.9320, model saved\n",
            "\n",
            "Epoch 7/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 1796/1796 [03:22<00:00,  8.89it/s]\n",
            "Evaluating: 100%|██████████| 449/449 [00:14<00:00, 30.19it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.1540, Train Acc: 94.20%\n",
            "Val Loss: 0.1583, Val Acc: 0.94%, Val F1: 0.9377\n",
            "✓ New best F1: 0.9377, model saved\n",
            "\n",
            "Epoch 8/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 1796/1796 [03:21<00:00,  8.92it/s]\n",
            "Evaluating: 100%|██████████| 449/449 [00:15<00:00, 29.67it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.1419, Train Acc: 94.59%\n",
            "Val Loss: 0.1557, Val Acc: 0.94%, Val F1: 0.9374\n",
            "\n",
            "Epoch 9/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 1796/1796 [03:27<00:00,  8.64it/s]\n",
            "Evaluating: 100%|██████████| 449/449 [00:14<00:00, 30.31it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.1319, Train Acc: 95.03%\n",
            "Val Loss: 0.1432, Val Acc: 0.94%, Val F1: 0.9427\n",
            "✓ New best F1: 0.9427, model saved\n",
            "\n",
            "Epoch 10/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 1796/1796 [03:21<00:00,  8.91it/s]\n",
            "Evaluating: 100%|██████████| 449/449 [00:14<00:00, 30.49it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.1236, Train Acc: 95.41%\n",
            "Val Loss: 0.1381, Val Acc: 0.94%, Val F1: 0.9439\n",
            "✓ New best F1: 0.9439, model saved\n",
            "\n",
            "============================================================\n",
            "Best validation F1: 0.9439\n",
            "============================================================\n"
          ]
        }
      ],
      "source": [
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"TRAINING CNN MODEL\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(cnn_model.parameters(), lr=2e-5)\n",
        "\n",
        "num_epochs = 10\n",
        "best_f1 = 0\n",
        "patience = 3\n",
        "patience_counter = 0\n",
        "\n",
        "train_losses = []\n",
        "val_losses = []\n",
        "train_accs = []\n",
        "val_accs = []\n",
        "val_f1s = []\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    print(f\"\\nEpoch {epoch+1}/{num_epochs}\")\n",
        "\n",
        "    train_loss, train_acc = train_epoch(cnn_model, train_loader, criterion, optimizer, device)\n",
        "    val_loss, val_acc, val_f1, _, _ = evaluate(cnn_model, val_loader, criterion, device)\n",
        "\n",
        "    train_losses.append(train_loss)\n",
        "    val_losses.append(val_loss)\n",
        "    train_accs.append(train_acc)\n",
        "    val_accs.append(val_acc)\n",
        "    val_f1s.append(val_f1)\n",
        "\n",
        "    print(f\"Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.2f}%\")\n",
        "    print(f\"Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.2f}%, Val F1: {val_f1:.4f}\")\n",
        "\n",
        "    if val_f1 > best_f1:\n",
        "        best_f1 = val_f1\n",
        "        patience_counter = 0\n",
        "        torch.save(cnn_model.state_dict(), 'best_cnn_model.pth')\n",
        "        print(f\"✓ New best F1: {best_f1:.4f}, model saved\")\n",
        "    else:\n",
        "        patience_counter += 1\n",
        "        if patience_counter >= patience:\n",
        "            print(f\"Early stopping after {epoch+1} epochs\")\n",
        "            break\n",
        "\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(f\"Best validation F1: {best_f1:.4f}\")\n",
        "print(\"=\" * 60)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DNbnlDyhc4X9"
      },
      "source": [
        "## Test Set Evaluation\n",
        "\n",
        "Final model evaluation on the test set with metrics (accuracy, F1-score, precision, recall) and confusion matrix.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 928
        },
        "id": "hthOWFvFc4X9",
        "outputId": "84811ec6-fcfd-4334-f810-4e6220ea0f98"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Evaluating CNN model on test set:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating: 100%|██████████| 562/562 [00:19<00:00, 29.48it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test Results:\n",
            "  Loss: 0.1337\n",
            "  Accuracy: 0.9475\n",
            "  F1-Score: 0.9476\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        Real       0.93      0.96      0.95      4283\n",
            "        Fake       0.96      0.94      0.95      4695\n",
            "\n",
            "    accuracy                           0.95      8978\n",
            "   macro avg       0.95      0.95      0.95      8978\n",
            "weighted avg       0.95      0.95      0.95      8978\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x600 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "CNN Results: {'test_loss': 0.13370104292072058, 'test_accuracy': 0.9475384272666518, 'test_f1': 0.9475609156959364, 'test_precision': 0.9479053392943768, 'test_recall': 0.9475384272666518}\n"
          ]
        }
      ],
      "source": [
        "cnn_model.load_state_dict(torch.load('best_cnn_model.pth'))\n",
        "\n",
        "print(\"\\nEvaluating CNN model on test set:\")\n",
        "test_loss, test_acc, test_f1, test_preds, test_labels = evaluate(\n",
        "    cnn_model, test_loader, criterion, device\n",
        ")\n",
        "\n",
        "print(f\"\\nTest Results:\")\n",
        "print(f\"  Loss: {test_loss:.4f}\")\n",
        "print(f\"  Accuracy: {test_acc:.4f}\")\n",
        "print(f\"  F1-Score: {test_f1:.4f}\")\n",
        "\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(test_labels, test_preds, target_names=['Real', 'Fake']))\n",
        "\n",
        "# Confusion Matrix\n",
        "cm = confusion_matrix(test_labels, test_preds)\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Greens',\n",
        "            xticklabels=['Real', 'Fake'], yticklabels=['Real', 'Fake'])\n",
        "plt.title('CNN - Confusion Matrix')\n",
        "plt.ylabel('True Label')\n",
        "plt.xlabel('Predicted Label')\n",
        "plt.show()\n",
        "\n",
        "cnn_results = {\n",
        "    'test_loss': float(test_loss),\n",
        "    'test_accuracy': float(test_acc),\n",
        "    'test_f1': float(test_f1),\n",
        "    'test_precision': float(precision_score(test_labels, test_preds, average='weighted')),\n",
        "    'test_recall': float(recall_score(test_labels, test_preds, average='weighted'))\n",
        "}\n",
        "\n",
        "print(f\"\\nCNN Results: {cnn_results}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s9qMtGyrasdB"
      },
      "source": [
        "## Download Model for Railway Deployment\n",
        "\n",
        "After training, download the best CNN model file for deployment on Railway.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "YVqlKcKzasdB",
        "outputId": "f30d951c-a236-4e04-c3fd-d4515c2095df",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 208
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✓ Model file found: best_cnn_model.pth\n",
            "  File size: 7.45 MB\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_bc79ad91-8bd9-4cf0-a1d8-630ec1b778ad\", \"best_cnn_model.pth\", 7815922)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "✓ MODEL DOWNLOADED!\n",
            "============================================================\n",
            "\n",
            "Next steps:\n",
            "1. The best_cnn_model.pth file should be downloaded to your Downloads folder\n",
            "2. Copy it to the models/ folder in your project\n",
            "3. The path should be: Fake-News-Classifier-2/models/best_cnn_model.pth\n"
          ]
        }
      ],
      "source": [
        "# Download CNN model for Railway deployment\n",
        "from google.colab import files\n",
        "import os\n",
        "\n",
        "model_path = 'best_cnn_model.pth'\n",
        "\n",
        "if os.path.exists(model_path):\n",
        "    print(f\"✓ Model file found: {model_path}\")\n",
        "    print(f\"  File size: {os.path.getsize(model_path) / (1024*1024):.2f} MB\")\n",
        "\n",
        "    # Download the file\n",
        "    files.download(model_path)\n",
        "\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"✓ MODEL DOWNLOADED!\")\n",
        "    print(\"=\"*60)\n",
        "    print(\"\\nNext steps:\")\n",
        "    print(\"1. The best_cnn_model.pth file should be downloaded to your Downloads folder\")\n",
        "    print(\"2. Copy it to the models/ folder in your project\")\n",
        "    print(\"3. The path should be: Fake-News-Classifier-2/models/best_cnn_model.pth\")\n",
        "else:\n",
        "    print(f\"⚠ Warning: Model file not found at {model_path}\")\n",
        "    print(\"Make sure training has been completed successfully.\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}